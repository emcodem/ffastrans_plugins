const fs = require("fs");
const path = require('path')
var md2 = require('js-md2');

//read input job customticket
let rawdata = fs.readFileSync(process.argv[2],'utf8').replace(/^\uFEFF/, ""); //get rid of UTF8 BOM

let o_job = JSON.parse(rawdata);
if (! ("variables" in o_job)){
    o_job["variables"] = []
}

//GET INPUTS - make them available as global objects
var hide_mainbranch = filterById(o_job["proc_data"]["inputs"],"hide_mainbranch");
var input_list = filterById(o_job["proc_data"]["inputs"],"list");

try{input_list  = JSON.parse(input_list.value)
	console.log("Input list:",input_list);
}catch(ex){
	console.log("Input List empty or not parseable");
	process.exit(1);
}

// Disabled until we have a foreach end
// var foreach_id = filterById(o_job["proc_data"]["inputs"],"foreach_id");
// foreach_id  = JSON.parse(foreach_id.value);
// console.log("Input ForeachId:",foreach_id);

//create branches
for (var _idx = 0; _idx<input_list.length;_idx++){
    create_subjob(_idx,input_list[_idx]);
}

//modify current ticket so the main branch does not go on 

o_job["proc_data"]["outputs"].push({"value":"s_end_branch","data":"true"}); //forcefully ends the main branch with success
if (hide_mainbranch["value"] == false){
	o_job["proc_data"]["outputs"].push({"value":"s_source","data":o_job["sources"]["current_file"]});
	o_job["proc_data"]["outputs"].push({"value":"s_success","data":"Success creating " + input_list.length + " Brances"});
}

//write output json for main branch
var outfile = fs.createWriteStream(o_job["processor_output_filepath"], {flags : 'w'});
outfile.write(JSON.stringify(o_job)) ;

//END


function end_with_errror(msg){
	//reset outputs so we dont write an empty s_source or such
	o_job["proc_data"]["outputs"] = []
	o_job["proc_data"]["outputs"].push({"value":"s_job_error_msg","data":msg}) 
	
	console.log("Ending with error, writing output file, ",o_job["processor_output_filepath"])
	fs.writeFileSync(o_job["processor_output_filepath"], JSON.stringify(o_job))
	process.exit(2);
}

function create_subjob(sub_index,sub_value){
    console.log("Working on ",sub_value);
    var this_ticket_file = o_job["ticket_file"];
    console.log("ticket_file",this_ticket_file)
    var o_this_ticket = JSON.parse(fs.readFileSync(this_ticket_file,'utf8').replace(/^\uFEFF/, ""));
    
    var cache_dir = o_job["cache_dir"];
    var this_jobguid = o_job["job_id"] || o_job["id"];
    var q_dir = cache_dir + "tickets\\queue";
    console.log("Queue dir: ", q_dir);
    var workflow_json_path = cache_dir + "\\jobs\\" + this_jobguid + "\\workflow.json";
    rawdata = fs.readFileSync(workflow_json_path,'utf8').replace(/^\uFEFF/, ""); //get rid of UTF8 BOM
     //fs.writeFileSync("c:\\temp\\processorticket.json",rawdata)
    var o_workflow = JSON.parse(rawdata);

    //get own node from jobticket
    var this_nodeid = o_job["nodes"]["next"]["id"];
    //get next node from workflow
    var o_this_node = filterById(o_workflow["nodes"],this_nodeid);
    //get outbounds of self node in workflow
    var a_outbounds = o_this_node["outbounds"];
	if (a_outbounds == null){
		end_with_errror("No outbound processors detected");
	}
    if (a_outbounds.length == 0){
        console.log("This Node Json:",o_this_node);
		end_with_errror("You must connect a Processor Node to the Foreach processor");
	}
	if (a_outbounds.length != 1){
        console.log("This Node Json:",o_this_node);
		end_with_errror("You can only connect a single Node on outbound to Foreach Node.");
	}
    var o_next_node = filterById(o_workflow["nodes"],o_this_node["outbounds"][0]["id"]);
    if (o_next_node["bypass"] ){
        end_with_errror("The next Node after Foreach cannot be bypassed");
    }
    //create one new job ticket per stuff in array
    var s_new_ticket_path = this_ticket_file;
    s_new_ticket_path = s_new_ticket_path.replace("tickets\\running","tickets\\temp");

    //set parent node to current node
    o_this_ticket["nodes"]["parent"] = o_job["nodes"]["next"];
    //set next node to next from workflow
    console.log("Outbounds",a_outbounds )
    o_this_ticket["nodes"]["next"] = a_outbounds[0];
    o_this_ticket["nodes"]["next"]["name"] = "Generated by Foreach"

    //push current node into path
	console.log("PATH",o_this_ticket["path"])
	if (! ("path" in o_this_ticket) || o_this_ticket["path"] == "undefined"){
		end_with_errror("Foreach cannot be the first processor of your workflow");
	}
    o_this_ticket["path"].push(o_job["nodes"]["next"]);
		
	//set variables in the new split job ticket 
	 o_job["proc_data"]["outputs"].forEach(function(_output){
		 if (!("variables" in o_this_ticket)){
			 o_this_ticket["variables"] = [];
		 }
		 //TODO:replace already existing vars
		 
		 //fill in targetvar into foreach ticket, %s_source% needs special attention
		 var tgtvar = filterById(o_job["proc_data"]["outputs"],"targetvar");
		 console.log("tgtvar",tgtvar["value"])
		 var existing_targetvar = filterByName(o_this_ticket["variables"],tgtvar["value"].replace(/\%/g,''));
		 if (!existing_targetvar){
			 o_this_ticket["variables"].push( {"name":tgtvar["value"].replace(/\%/g,''), "data":  sub_value} );//id,value,data
		 }else{
			 existing_targetvar["data"] = sub_value;
		 }
		 
		if (tgtvar["value"] == "%s_source%"){
			o_this_ticket["sources"]
			o_this_ticket["sources"]["current_file"] = sub_value;
			o_this_ticket["sources"]["original_file"] = sub_value;
			o_this_ticket["sources"]["localized_file"] = sub_value;
			o_this_ticket["sources"]["pretty_name"] = path.basename(sub_value);
		}
		//fill in countvar into foreach ticket
		 var tgtcount = filterById(o_job["proc_data"]["outputs"],"targetcount"); //get variable name from userinputs
		 var existing_countvar = filterByName(o_this_ticket["variables"],tgtcount["value"].replace(/\%/g,''));
		 if (!existing_countvar){
			 o_this_ticket["variables"].push( {"name":tgtcount["value"].replace(/\%/g,''), "data":  sub_value} );//id,value,data
		 }else{
			 existing_countvar["data"] = sub_index;
		 }
	 });
	
	//fs.writeFileSync("c:\\temp\\nexttickete.json", JSON.stringify(o_this_ticket), { mode: 0o755 });
    //calculate new split_id
    var s_id = o_this_ticket["split_id"].split("-");
    s_id[0] = s_id + sub_index + "f"; //!! alter first part of splitid and append current index
    o_this_ticket["split_id"] = s_id.join('-'); 
    var _md2 = md2(JSON.stringify(o_this_ticket)).toUpperCase();
    _md2 = _md2.substring(_md2.length-6)
    s_new_ticket_path = s_new_ticket_path.replace(/......\.json/,_md2+".json")
    console.log("Writing ticket: ",s_new_ticket_path)
    fs.writeFileSync(s_new_ticket_path, JSON.stringify(o_this_ticket), { mode: 0o755 });
    var s_ticket_temp_path = s_new_ticket_path;
	//move the ticket from them to queue
    s_new_ticket_path = s_new_ticket_path.replace("tickets\\temp","tickets\\queue");
    fs.rename(s_ticket_temp_path, s_new_ticket_path, function(){});
	
}


function filterByName(array, string) {
//finds by key in input variable array
    for (idx in array){
        if (array[idx].name == string){
            return array[idx];
        }
    }
	return false;
}

function filterById(array, string) {
//finds by key in input variable array
    for (idx in array){
        if (array[idx].id == string){
            return array[idx];
        }
    }
}
